# MCM/ICM 2026 模型库终极指南 (MODELS LIST)

**版本**: 1.0 (2026年1月28日更新)  
**包含技能**: 28个核心技能  
**适用对象**: MCM/ICM 参赛队伍、数学建模爱好者

---

本文档旨在为参赛者提供一份详尽的 **MCM/ICM 技能体（Models）使用指南**。所有模型均已封装为标准化的 "Skill"，可直接调用。文档按照比赛的标准流程分为四大阶段：**前期数据处理**、**中期模型构建**、**后期验证与分析**、以及**论文产出**。

---

## 📅 第一阶段：前期数据处理 (Data Pre-processing)

数据是建模的基础。在开始任何复杂模型之前，必须确保数据的质量和可用性。

### 1. **data-cleaner** (数据清洗专家)
- **技能定位**: 自动化数据预处理工具，处理脏数据、缺失值和异常值。
- **核心要求**: 
  - 输入数据必须是结构化的 (CSV/Excel)。
  - 需要识别并处理缺失值（插值、删除或填充）。
  - 需要检测并处理异常值（3-sigma或IQR原则）。
- **适用数据**: 原始的、未清洗的CSV或Excel文件，包含空值、格式错误或离群点。
- **使用场景**:
  - **Before**: 刚从网站爬取或下载了原始数据。
  - **Action**: 调用 `data-cleaner` 进行自动化清洗。
  - **After**: 得到 `processed.csv`，作为所有后续模型的输入。
- **实现策略**: 使用 Pandas 进行向量化操作，自动生成数据质量报告。

### 2. **pca-analyzer** (主成分分析器)
- **技能定位**: 降维工具，用于简化高维数据，消除多重共线性。
- **核心要求**:
  - 保留85%以上的累计方差贡献率。
  - 解释主成分的实际含义（例如：第一主成分代表"经济实力"，第二主成分代表"环境压力"）。
- **适用数据**: 指标数量过多（通常>10个）且存在相关性的高维数据。
- **使用场景**:
  - **Before**: 收集了20个经济指标，但担心模型过拟合。
  - **Action**: 使用 `pca-analyzer` 将20个指标压缩为3-4个综合指标。
  - **After**: 将降维后的数据输入到评价模型（如TOPSIS）或回归模型（如ML Regressor）。
- **实现策略**: 基于 `sklearn.decomposition.PCA`，自动计算特征值和载荷矩阵。

---

## ⚙️ 第二阶段：中期模型构建 (Mid-stage Modeling)

这是比赛的核心部分。根据题目类型选择合适的模型类别。

### A. 评价与决策类 (Evaluation & Decision)
适用于 Problem D/E/F 或任何需要排名、打分、选优的问题。

#### 3. **entropy-weight-method** (熵权法)
- **技能定位**: 客观赋权方法，完全基于数据本身的变异程度。
- **核心要求**: 数据不能有负数（需归一化），权重和为1。
- **适用数据**: 没有任何专家经验参考的纯数据指标。
- **使用场景**: 当你不希望主观因素干扰权重计算时。通常与 TOPSIS 结合使用。

#### 4. **ahp-method** (层次分析法)
- **技能定位**: 主观赋权方法，基于专家（其实就是你）对指标重要性的两两比较。
- **核心要求**: 
  - 一致性比例 (CR) 必须 < 0.1。
  - 构造的判断矩阵必须通过一致性检验。
- **适用数据**: 难以量化的定性指标（如"风景优美程度"、"政策支持力度"）。
- **使用场景**: 需要体现"专家经验"或处理定性指标时。

#### 5. **topsis-scorer** (优劣解距离法)
- **技能定位**: 综合评价与排名工具，计算各方案与"理想解"的距离。
- **核心要求**: 正向化所有指标（越大越好），标准化处理。
- **经典组合**: **Entropy-AHP-TOPSIS 模型**。
  - **流程**: 先用熵权法算客观权重 → 再用AHP算主观权重 → 综合权重 → 输入TOPSIS进行最终排名。
- **实现策略**: 向量化计算欧氏距离，生成相对贴近度分数。

---

### B. 预测与时间序列类 (Forecasting & Time Series)
适用于 Problem C 或需要对未来趋势进行预判的问题。

#### 6. **grey-forecaster** (灰色预测 GM(1,1))
- **技能定位**: "贫信息"预测模型，专门处理极少数据样本。
- **核心要求**: 
  - 样本量在 4-10 个之间。
  - 数据必须全部为正。
  - 后验差比 (C值) 需 < 0.35 以保证精度。
- **适用数据**: 短期数据、小样本数据（如仅有过去5年的数据）。
- **使用场景**: 题目只给了很少的历史数据，但要求预测未来2-3年的趋势。

#### 7. **arima-forecaster** (时间序列分析)
- **技能定位**: 经典的统计学预测模型，擅长捕捉线性趋势和季节性。
- **核心要求**: 
  - 样本量建议 > 50。
  - 数据需要通过平稳性检验 (ADF test)。
- **适用数据**: 具有明显趋势或周期性的长序列数据。
- **使用场景**: 预测股票价格、气温变化、GDP增长等具有充足历史数据的指标。

#### 8. **lstm-forecaster** (深度学习预测)
- **技能定位**: 基于长短期记忆网络 (LSTM) 的非线性预测模型。
- **核心要求**: 
  - 大量数据（建议 > 500点）以避免过拟合。
  - 需要划分训练集和测试集验证泛化能力。
- **适用数据**: 复杂的、非线性的、具有长期依赖关系的时序数据。
- **使用场景**: 传统统计模型失效，或者需要展示"高大上"的AI能力时。

#### 9. **ml-regressor** (机器学习回归)
- **技能定位**: 基于随机森林或 XGBoost 的非线性回归与预测。
- **核心要求**: 
  - 输出特征重要性 (Feature Importance) 以增加可解释性。
  - 使用交叉验证 (Cross-Validation) 评估误差。
- **适用数据**: 自变量和因变量之间存在复杂的非线性交互关系。
- **使用场景**: 预测房价、销售额，或者找出影响结果的"关键驱动因素"。

---

### C. 机理与微分方程类 (Mechanistic & Differential Equations)
适用于 Problem A 或涉及物理、生物、化学过程的动态演化问题。

#### 10. **logistic-growth** (Logistic 增长模型)
- **技能定位**: 描述资源受限条件下的单一种群增长（S型曲线）。
- **核心要求**: 必须估计环境承载力 (K值)。
- **适用数据**: 早期指数增长，后期趋于饱和的数据。
- **使用场景**: 人口预测、产品市场占有率预测、传染病早期传播。

#### 11. **lotka-volterra** (捕食者-猎物模型)
- **技能定位**: 描述两个种群之间的竞争或捕食关系。
- **核心要求**: 分析平衡点的稳定性，绘制相图 (Phase Portrait)。
- **适用数据**: 两个相互影响的时间序列（如狼和兔子的数量）。
- **使用场景**: 生态平衡分析、商业竞争模型（公司A vs 公司B）。

#### 12. **reaction-diffusion** (反应扩散方程)
- **技能定位**: 描述物质在空间上的扩散和局部的反应过程。
- **核心要求**: 生成 2D/3D 时空演化图或视频。
- **适用数据**: 需要考虑空间分布的动态过程。
- **使用场景**: 传染病的空间传播、污染物的扩散、斑图生成、生态入侵。

#### 13. **differential-equations** (通用微分方程求解器)
- **技能定位**: 统一的 ODE/PDE 求解框架，是上述三个模型的底层引擎。
- **核心要求**: 将文字描述的机理转化为数学方程组。
- **使用场景**: 当标准模型（如Logistic）无法满足需求，需要自定义方程组时。

---

### D. 网络与图论类 (Network & Graph Theory)
适用于 Problem D (Network) 或涉及物流、社交网络分析的问题。

#### 14. **shortest-path** (最短路径算法)
- **技能定位**: 寻找网络中最优路径的基础算法库 (Dijkstra / Floyd / Bellman-Ford / A*)。
- **核心要求**: 
  - 明确图的类型（有向/无向，加权/非加权）。
  - 对负权边选择正确的算法（Bellman-Ford）。
- **适用数据**: 节点（城市/路口）和边（道路/航线）及其权重（距离/成本）。
- **使用场景**: 物流配送路径规划、应急救援路线、交通网络优化。
- **经典流程**: 构建邻接矩阵 → 调用 `shortest-path` → 得到距离矩阵或具体路径 → 输入到更复杂的优化模型（如遗传算法求解VRP）。

#### 15. **network-centrality** (网络中心性分析)
- **技能定位**: 识别复杂网络中的"关键节点"和"影响力人物"。
- **核心要求**: 计算多个维度的中心性（度、介数、接近、特征向量）。
- **适用数据**: 社交网络关系、基础设施连接图、引文网络。
- **使用场景**: 找出社交网络中的意见领袖、电网中的脆弱节点、疫情传播中的超级传播者。
- **经典流程**: 构建网络图 → 调用 `network-centrality` → 得到节点排名 → 可视化关键节点 → 提出针对性策略（如保护关键节点或阻断传播）。

---

### E. 优化与规划类 (Optimization & Planning)
适用于 Problem B 或任何需要"求极值"、"资源配置"的问题。

#### 16. **genetic-algorithm** (遗传算法 GA)
- **技能定位**: 模拟自然进化的启发式算法，擅长离散和组合优化。
- **核心要求**: 设计合理的编码方式（染色体）和适应度函数。
- **适用场景**: 旅行商问题 (TSP)、选址问题、排班问题。
- **特点**: 全局搜索能力强，适合离散变量。

#### 17. **simulated-annealing** (模拟退火 SA)
- **技能定位**: 基于物理退火过程的随机搜索算法。
- **核心要求**: 设计合理的冷却进度表 (Cooling Schedule)。
- **适用场景**: 极其复杂的函数寻优，容易陷入局部最优的问题。
- **特点**: 原理简单，擅长跳出局部最优。

#### 18. **particle-swarm** (粒子群算法 PSO)
- **技能定位**: 模拟鸟群捕食的群体智能算法。
- **核心要求**: 调节惯性权重和学习因子。
- **适用场景**: 连续变量的函数优化，参数拟合。
- **特点**: 收敛速度快，实现简单，适合连续空间搜索。

#### 19. **multi-objective-optimization** (多目标优化 NSGA-II)
- **技能定位**: 同时优化多个冲突目标（如：成本最低且质量最好）。
- **核心要求**: 寻找 Pareto 前沿面 (Pareto Frontier)。
- **使用场景**: 当在这个世界上"既要...又要..."无法同时满足时。
- **输出**: 不是一个解，而是一组非支配解集供决策者选择。

---

## ✅ 第三阶段：后期验证与分析 (Validation & Analysis)

这是区分 O-Prize 和普通奖项的关键。必须证明模型的稳健性。

### 20. **sensitivity-master** (灵敏度分析专家)
- **技能定位**: 全局灵敏度分析（Sobol / Morris 方法）。
- **核心要求**: 识别出哪个参数对结果影响最大。
- **使用场景**: 模型建好后，改变关键参数（如 ±10%），观察结果变化幅度。
- **O-Prize 标准**: 不仅做单因素分析，还要做多因素交互分析 (Sobol indices)。

### 21. **robustness-check** (鲁棒性检验)
- **技能定位**: 验证模型在极端或干扰条件下的稳定性。
- **使用场景**: "如果我的假设稍微不成立，模型会崩溃吗？"
- **输出**: 龙卷风图 (Tornado Diagram)、相平面分析。

### 22. **monte-carlo-engine** (蒙特卡洛模拟)
- **技能定位**: 不确定性量化。
- **使用场景**: 给定参数的概率分布，模拟成千上万次，得到结果的置信区间。
- **输出**: "结果有 95% 的概率落在 [X, Y] 区间内"。

### 23. **automated-sweep** (自动化参数扫描)
- **技能定位**: 暴力网格搜索，寻找最优参数组合。
- **使用场景**: 在模型参数未知时，通过扫描寻找使误差最小的参数值。

### 24. **pareto-frontier** (Pareto 前沿可视化)
- **技能定位**: 多目标优化的可视化工具。
- **使用场景**: 画出 trade-off 曲线，直观展示目标之间的制约关系。

### 25. **modular-modeler** (模块化建模架构)
- **技能定位**: 复杂系统建模的 OOP 框架。
- **使用场景**: 当模型非常庞大，需要多人协作开发时，将其拆分为独立的模块。

---

## 📝 第四阶段：论文产出 (Post-processing)

最后一步，将模型转化为漂亮的论文。

### 26. **visual-engineer** (可视化专家)
- **技能定位**: 生成出版级质量的图表。
- **核心要求**: 300 DPI, Times New Roman 字体，配色符合学术规范。
- **使用场景**: 替换掉所有 Python/Matplotlib 默认生成的丑陋图表。

### 27. **latex-transformer** (LaTeX 转换器)
- **技能定位**: 将 Markdown 草稿转化为 LaTeX 代码。
- **使用场景**: 快速生成三线表、公式代码、参考文献引用格式。

---

## 🛠️ 元技能 (Meta Skill)

### 28. **skill-creator** (技能创造者)
- **技能定位**: 用于创建新技能的模板和指南。
- **使用场景**: 当你需要扩展这个模型库时使用。

---

## 🚀 经典调用流程示例

**场景 1：传染病防控策略优化**
1. **数据处理**: `data-cleaner` 清洗疫情数据。
2. **建模**: `differential-equations` 建立 SIR 模型，或 `reaction-diffusion` 建立空间传播模型。
3. **参数估计**: `automated-sweep` 利用历史数据反向拟合模型参数（如感染率）。
4. **验证**: `sensitivity-master` 分析 R0 对隔离强度的敏感性。
5. **产出**: `visual-engineer` 绘制疫情预测曲线和置信区间 (`monte-carlo-engine`)。

**场景 2：物流中心选址与路径规划**
1. **网络构建**: `data-cleaner` 处理城市坐标数据，`shortest-path` 计算所有点对距离矩阵。
2. **中心性分析**: `network-centrality` 识别交通枢纽作为候选中心。
3. **优化**: `genetic-algorithm` 或 `simulated-annealing` 在候选点中寻找成本最低的选址方案。
4. **评估**: `entropy-weight-method` + `topsis-scorer` 对不同选址方案进行综合打分。
5. **产出**: 论文中展示选址结果地图和成本分析图表。

**场景 3：可持续发展政策制定**
1. **指标构建**: `pca-analyzer` 对几十个发展指标进行降维。
2. **预测**: `lstm-forecaster` 预测未来10年的发展趋势。
3. **优化**: `multi-objective-optimization` 寻找经济增长与环境保护的 Pareto 平衡点。
4. **决策**: `pareto-frontier` 可视化展示不同政策的后果。
5. **验证**: `robustness-check` 证明政策在极端气候下的有效性。

---

**保存位置**: `.github/skills/MODELS_LIST.md`
